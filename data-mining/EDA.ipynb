{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>last week tonight trump presidency|\"last week ...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>rhett and link|\"gmm\"|\"good mythical morning\"|\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d380meD0W0M</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T18:01:41.000Z</td>\n",
       "      <td>ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...</td>\n",
       "      <td>2095731</td>\n",
       "      <td>132235</td>\n",
       "      <td>1989</td>\n",
       "      <td>17518</td>\n",
       "      <td>https://i.ytimg.com/vi/d380meD0W0M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I know it's been a while since we did this sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE      17.14.11   \n",
       "1  1ZAPwfrtAFY      17.14.11   \n",
       "2  5qpjK5DgCt4      17.14.11   \n",
       "3  puqaWrEC7tY      17.14.11   \n",
       "4  d380meD0W0M      17.14.11   \n",
       "\n",
       "                                               title          channel_title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "4                           I Dare You: GOING BALD!?               nigahiga   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           22  2017-11-13T17:13:01.000Z   \n",
       "1           24  2017-11-13T07:30:00.000Z   \n",
       "2           23  2017-11-12T19:05:24.000Z   \n",
       "3           24  2017-11-13T11:00:04.000Z   \n",
       "4           24  2017-11-12T18:01:41.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  last week tonight trump presidency|\"last week ...  2418783   97185   \n",
       "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434  146033   \n",
       "3  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   10172   \n",
       "4  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731  132235   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "4      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1  One year after the presidential election, John...  \n",
       "2  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
       "3  Today we find out if Link is a Nickelback amat...  \n",
       "4  I know it's been a while since we did this sho...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read files\n",
    "unprocessed_df = pd.read_csv(\"../Data/US_videos.csv\")\n",
    "\n",
    "# read json file\n",
    "with open(\"../Data/US_category_id.json\") as train_file:\n",
    "    categories = json.load(train_file)[\"items\"]\n",
    "unprocessed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_category_id(categories):\n",
    "    \"\"\"\"\n",
    "    \n",
    "    Get descriptions of the category ids\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    categories: dataframe\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Dataframe with a new column of categories descriptions\n",
    "    \"\"\"\n",
    "    cat_dict = {}\n",
    "    for cat in categories:\n",
    "        cat_dict[int(cat[\"id\"])] = cat[\"snippet\"][\"title\"]\n",
    "    return cat_dict\n",
    "\n",
    "cat_dict = get_category_id(categories)\n",
    "unprocessed_df['category_name'] = unprocessed_df['category_id'].map(cat_dict)\n",
    "unprocessed_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Filter for the last row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_latest_update_video_id(df):\n",
    "    \"\"\"\"\n",
    "    \n",
    "    Get latest updated row corresponding to a video\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Dataframe at a video id level\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = df.groupby(['video_id'])['trending_date'].transform(max) == df['trending_date']\n",
    "\n",
    "    df = df[idx]\n",
    "    return df\n",
    "unprocessed_df = get_latest_update_video_id(unprocessed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def missing_value_checker(df):\n",
    "    \"\"\"\n",
    "    The missing value checker\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    The variables with missing value and their proportion of missing value\n",
    "    \"\"\"\n",
    "    \n",
    "    variable_proportion = [[variable, df[variable].isna().sum() / df.shape[0]] \n",
    "                           for variable in df.columns \n",
    "                           if df[variable].isna().sum() > 0]\n",
    "\n",
    "    print('%-30s' % 'Variable with missing values', 'Proportion of missing values')\n",
    "    for variable, proportion in sorted(variable_proportion, key=lambda x : x[1]):\n",
    "        print('%-30s' % variable, proportion)\n",
    "        \n",
    "    return variable_proportion\n",
    "variable_proportion = missing_value_checker(unprocessed_df)\n",
    "# Only desc has nulls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#df statistics\n",
    "unprocessed_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define popularity levels. The levels can be defined using #comments. #views, #likes and #dislikes. \n",
    "Lets analyze the distribution of these variables. As the scale of the variables is really high the variables are transformed\n",
    "on a log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unprocessed_df[['views_log', 'dislikes_log', 'likes_log']] = np.log(unprocessed_df[['views', 'dislikes', 'likes']] +1)\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.subplot(221)\n",
    "g1 = sns.distplot(unprocessed_df['views_log'])\n",
    "g1.set_title(\"VIEWS LOG DISTRIBUITION\", fontsize=16)\n",
    "\n",
    "plt.subplot(224)\n",
    "g2 = sns.distplot(unprocessed_df['likes_log'],color='green')\n",
    "g2.set_title('LIKES LOG DISTRIBUITION', fontsize=16)\n",
    "\n",
    "plt.subplot(223)\n",
    "g3 = sns.distplot(unprocessed_df['dislikes_log'], color='r')\n",
    "g3.set_title(\"DISLIKES LOG DISTRIBUITION\", fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection and treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_treatment(df):\n",
    "    \"\"\"\n",
    "    \n",
    "    Values lying outside 3SD are considered as outliers for this analysis\n",
    "    Outlier values are treated with mean of that column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Dataframe with treated outlier values\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in [\"likes\", \"dislikes\", \"views\", \"comment_count\"]:\n",
    "        outliers = df[(np.abs(stats.zscore(df[col]))>3)][col]\n",
    "        print(\"Total outlier points for \" +col+ \":\", len(outliers))\n",
    "        df.loc[outliers.index, col] = df[col].mean()\n",
    "    return df\n",
    "\n",
    "unprocessed_df = outlier_treatment(unprocessed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Month wise distribution for published time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unprocessed_df['publish_time'] = pd.to_datetime(unprocessed_df['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "unprocessed_df['published_month'] = unprocessed_df['publish_time'].dt.month\n",
    "# plt.subplot(211)\n",
    "# g = sns.lineplot(x = 'published_month', y = \"x\", data=unprocessed_df, palette=\"Set1\", estimator = lambda unprocessed_df: np.mean(unprocessed_df['views']))\n",
    "# g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "# g.set_title(\"Counting Months \", fontsize=20)\n",
    "# g.set_xlabel(\"Months\", fontsize=15)\n",
    "# g.set_ylabel(\"Count\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Months from june till Nov has very less published videos. Maximum videos are published in the month of May.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month wise distribution for trending date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unprocessed_df['trending_date'] = pd.to_datetime(unprocessed_df['trending_date'], format='%y.%d.%m')\n",
    "unprocessed_df['trending_month'] = unprocessed_df['trending_date'].dt.month\n",
    "\n",
    "# plt.subplot(211)\n",
    "# g = sns.countplot('trending_month', data=unprocessed_df, palette=\"Set1\")\n",
    "# g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "# g.set_title(\"Counting Months \", fontsize=20)\n",
    "# g.set_xlabel(\"Months\", fontsize=15)\n",
    "# g.set_ylabel(\"Count\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Months from june till Nov do not have trending data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day wise distribution for published time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unprocessed_df['publish_time_dayofweek'] = unprocessed_df['publish_time'].dt.dayofweek+1\n",
    "# plt.subplot(211)\n",
    "# g = sns.countplot('publish_time_dayofweek', data=unprocessed_df, palette=\"Set1\")\n",
    "# g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "# g.set_title(\"Counting dayofweek\", fontsize=20)\n",
    "# g.set_xlabel(\"Day of week\", fontsize=15)\n",
    "# g.set_ylabel(\"Count\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unprocessed_df['publish_weekend'] = unprocessed_df['publish_time_dayofweek']>5\n",
    "unprocessed_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Surprisingly weekends (6 & 7) has less published videos that weekdays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day wise distribution for trending date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unprocessed_df['trending_dayofweek'] = unprocessed_df['trending_date'].dt.dayofweek+1\n",
    "# \n",
    "# print(unprocessed_df['trending_dayofweek'].value_counts())\n",
    "# plt.subplot(211)\n",
    "# g = sns.countplot('trending_dayofweek', data=unprocessed_df, palette=\"Set1\")\n",
    "# g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "# g.set_title(\"Counting Months \", fontsize=20)\n",
    "# g.set_xlabel(\"Months\", fontsize=15)\n",
    "# g.set_ylabel(\"Count\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unprocessed_df['trending_weekend'] = unprocessed_df['trending_dayofweek']>5\n",
    "unprocessed_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All weeks have more or less same trending counts in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# separates date and time into two columns from 'publish_time' column\n",
    "unprocessed_df['time'] = unprocessed_df['publish_time'].dt.time\n",
    "\n",
    "unprocessed_df[['hour','min','sec']] = unprocessed_df['time'].astype(str).str.split(':', expand=True).astype(int)\n",
    "\n",
    "unprocessed_df['hour'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "g = sns.countplot('hour', data=unprocessed_df, palette=\"Set1\")\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "g.set_title(\"Counting Hour \", fontsize=20)\n",
    "g.set_xlabel(\"Hours\", fontsize=15)\n",
    "g.set_ylabel(\"Count\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(212)\n",
    "g = sns.countplot('category_name', data=unprocessed_df, palette=\"Set1\")\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "g.set_title(\"Counting Hour \", fontsize=20)\n",
    "g.set_xlabel(\"Category\", fontsize=15)\n",
    "g.set_ylabel(\"Count\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Maximum videos are published during 15,16,17 hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizing title data with wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (15,15))\n",
    "\n",
    "# stopwords = set(STOPWORDS)\n",
    "# wordcloud = WordCloud(\n",
    "#                           background_color='black',\n",
    "#                           stopwords=stopwords,\n",
    "#                         \n",
    "max_words=150,\n",
    "#                           max_font_size=40, \n",
    "#                           random_state=42\n",
    "#                          ).generate(str(unprocessed_df['title']))\n",
    "\n",
    "# print(wordcloud)\n",
    "# fig = plt.figure(1)\n",
    "# plt.imshow(wordcloud)\n",
    "# plt.title(\"WORD CLOUD - DESCRIPTION\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Word count in each comment:\n",
    "unprocessed_df['count_word']=unprocessed_df[\"title\"].apply(lambda x: len(str(x).split()))\n",
    "unprocessed_df['count_word_tags']=unprocessed_df[\"tags\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#Unique word count\n",
    "unprocessed_df['count_unique_word']=unprocessed_df[\"title\"].apply(lambda x: len(set(str(x).split())))\n",
    "unprocessed_df['count_unique_word_tags']=unprocessed_df[\"tags\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "unprocessed_df['count_tags']=unprocessed_df[\"tags\"].apply(lambda x: len(set(str(x).split(\"|\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def outcome(unprocessed_df, w1,w2,w3, num):\n",
    "    print(w3)\n",
    "    \n",
    "    unprocessed_df['neutral'] = unprocessed_df['views']-unprocessed_df['likes']-unprocessed_df['dislikes']\n",
    "    \n",
    "    y = w1*unprocessed_df['likes']+w2*unprocessed_df['neutral']+w3*unprocessed_df['dislikes']\n",
    "    y.sum()\n",
    "    unprocessed_df[\"y_cat_\"+ str(num)] =pd.qcut(y ,3,labels=[\"low\", \"medium\", \"high\"])  \n",
    "    return unprocessed_df\n",
    "\n",
    "unprocessed_df = outcome(unprocessed_df, 1/3,1/3,1/3, 1) # equally important\n",
    "unprocessed_df = outcome(unprocessed_df, 1/2,1/4,1/4, 2) # likes more important\n",
    "unprocessed_df = outcome(unprocessed_df, 1/2,3/8,1/8, 3) # likes more important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corr = unprocessed_df.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unprocessed_df['timediff'] = (unprocessed_df['trending_date'] - unprocessed_df['publish_time']).dt.days\n",
    "unprocessed_df['timediff'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = unprocessed_df['y_cat_2']\n",
    "X = unprocessed_df[['timediff', 'comments_disabled', 'ratings_disabled', 'comment_count',\n",
    "       'video_error_or_removed', 'category_name', 'published_month', 'trending_month',\n",
    "       'publish_weekend','trending_weekend','hour', 'count_word',\n",
    "       'count_tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def categorical_feature_checker(df, target, dtype):\n",
    "    \"\"\"\n",
    "    The categorical feature checker\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "    target : the target\n",
    "    dtype : the type of the feature\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    The categorical features and their number of unique value\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_number = [[feature, df[feature].nunique()] \n",
    "                      for feature in df.columns \n",
    "                      if feature != target and df[feature].dtype.name == dtype]\n",
    "    \n",
    "    print('%-30s' % 'Categorical feature', 'Number of unique value')\n",
    "    for feature, number in sorted(feature_number, key=lambda x : x[1]):\n",
    "        print('%-30s' % feature, number)\n",
    "    \n",
    "    return feature_number\n",
    "feature_number = categorical_feature_checker(X, target, 'object')\n",
    "\n",
    "# Print the unique value and their number for the target\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate train and test to predict the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clfs = {'lr': LogisticRegression(random_state=0),\n",
    "        'mlp': MLPClassifier(random_state=0),\n",
    "        'dt': DecisionTreeClassifier(random_state=0),\n",
    "        'rf': RandomForestClassifier(random_state=0),\n",
    "        'xgb': XGBClassifier(seed=0),\n",
    "        'svc': SVC(random_state=0),\n",
    "        'knn': KNeighborsClassifier(),\n",
    "        'gnb': GaussianNB()}\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe_clfs = {}\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    # Implement me\n",
    "    pipe_clfs[name] = Pipeline([('StandardScaler', StandardScaler()), ('clf', clf)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_grids = { }\n",
    "# logistic\n",
    "C_range = [10 ** i for i in range(-4, 5)]\n",
    "\n",
    "param_grid = [{'clf__multi_class': ['ovr'], \n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "               'clf__C': C_range},\n",
    "              \n",
    "              {'clf__multi_class': ['multinomial'],\n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'clf__C': C_range}]\n",
    "\n",
    "param_grids['lr'] = param_grid\n",
    "\n",
    "# MLP\n",
    "param_grid = [{'clf__hidden_layer_sizes': [10, 100],\n",
    "               'clf__activation': ['identity', 'logistic', 'tanh', 'relu']}]\n",
    "\n",
    "param_grids['mlp'] = param_grid\n",
    "\n",
    "# Decision tree\n",
    "param_grid = [{'clf__min_samples_split': [2, 10, 30],\n",
    "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "\n",
    "param_grids['dt'] = param_grid\n",
    "\n",
    "# Random forest\n",
    "param_grid = [{'clf__n_estimators': [10, 100],\n",
    "               'clf__min_samples_split': [2, 10, 30],\n",
    "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "\n",
    "param_grids['rf'] = param_grid\n",
    "\n",
    "# xgboost\n",
    "param_grid = [{'clf__learning_rate': [10 ** i for i in range(-4, 1)],\n",
    "               'clf__gamma': [0, 10, 100],\n",
    "               'clf__reg_lambda': [10 ** i for i in range(-4, 5)]}]\n",
    "\n",
    "param_grids['xgb'] = param_grid\n",
    "# SVC\n",
    "param_grid = [{'clf__C': [10 ** i for i in range(-4, 5)],\n",
    "               'clf__gamma': ['auto', 'scale']}]\n",
    "\n",
    "param_grids['svc'] = param_grid\n",
    "\n",
    "#Knn\n",
    "param_grid = [{'clf__n_neighbors': list(range(1, 11))}]\n",
    "\n",
    "param_grids['knn'] = param_grid\n",
    "\n",
    "#GNB\n",
    "param_grid = [{'clf__var_smoothing': [10 ** i for i in range(-10, -7)]}]\n",
    "\n",
    "param_grids['gnb'] = param_grid\n",
    "param_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# The list of [best_score_, best_params_, best_estimator_]\n",
    "best_score_param_estimators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data = X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# For each classifier\n",
    "best_score_param_estimators = []\n",
    "for name in pipe_clfs.keys():\n",
    "    # GridSearchCV\n",
    "    # Implement me\n",
    "    gs = GridSearchCV(estimator=pipe_clfs[name],\n",
    "                      param_grid=param_grids[name],\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=1,\n",
    "                      iid=False,\n",
    "                      cv=StratifiedKFold(n_splits=5,\n",
    "                                         shuffle=True,\n",
    "                                         random_state=0))\n",
    "    # Fit the pipeline\n",
    "    # Implement me\n",
    "    gs = gs.fit(X, y)\n",
    "    # Update best_score_param_estimators\n",
    "    best_score_param_estimators.append([gs.best_score_, gs.best_params_, gs.best_estimator_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_score_param_estimators = sorted(best_score_param_estimators, key=lambda x : x[0], reverse=True)\n",
    "\n",
    "# For each [best_score_, best_params_, best_estimator_]\n",
    "for best_score_param_estimator in best_score_param_estimators:\n",
    "    # Print out [best_score_, best_params_, best_estimator_], where best_estimator_ is a pipeline\n",
    "    # Since we only print out the type of classifier of the pipeline\n",
    "    print([best_score_param_estimator[0], best_score_param_estimator[1], type(best_score_param_estimator[2].named_steps['clf'])], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_estimator.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from pydotplus import graph_from_dot_data\n",
    "# from sklearn.tree import export_graphviz\n",
    "# from IPython.display import Image\n",
    "# feature_value_names = X.columns\n",
    "# dot_data = export_graphviz(best_estimator.named_steps['clf'],\n",
    "#                            filled=True, \n",
    "#                            rounded=True,\n",
    "#                            feature_names=feature_value_names) \n",
    "\n",
    "# graph = graph_from_dot_data(dot_data) \n",
    "\n",
    "# Image(graph.create_png()) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Convert the importances into one-dimensional 1darray with corresponding df column names as axis labels\n",
    "# f_importances = pd.Series(best_estimator.named_steps['clf'].feature_importances_, feature_value_names)\n",
    "\n",
    "# # Sort the array in descending order of the importances\n",
    "# f_importances = f_importances.sort_values(ascending=False)\n",
    "\n",
    "# # Draw the bar Plot from f_importances \n",
    "# f_importances.plot(x='Features', y='Importance', kind='bar', figsize=(16,9), rot=45, fontsize=30)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
